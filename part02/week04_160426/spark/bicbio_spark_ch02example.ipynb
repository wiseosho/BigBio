{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 도커로 스파크(with jupyter notebook) 시작하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sudo docker run -d -p [외부포트]:[컨테이너내부포트] -e GRANT_SUDO=yes --name [컨테이너 이름] jupyter/all-spark-notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저는 biospark 라는 이름으로, 외부포트를 9999로 변경하여 실행해보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " sudo docker run -d -p 9999:8888 -e GRANT_SUDO=yes --name biospark jupyter/all-spark-notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "도커 쉘에서 위와 같이 실행한 후,  \n",
    "크롬 등 인터넷 브라우저에서 ip:9999 실행하시면 jupyter notebook 환경이 뜹니다.  \n",
    "ip는 서버 사용하시는 서버의 ip를 사용하시면 되고  \n",
    "윈도우나 맥에서 docker-machine 사용하시는 경우, docker-machine ip default 로 ip 확인하시면 됩니다.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출처 : http://yujuwon.tistory.com/entry/spark-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 초기화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext() # SparkContext 객체가 sc 변수에 만들어진다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7fb769907750>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc # sc를 입력하여 다음과 같은 결과가 나오면 성공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text.txt 파일 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%writefile 을 이용하면 쥬피터 노트북에서 쉽게 예제로 사용할 txt 파일을 만들수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting text.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile text.txt\n",
    "this is first line\n",
    "this is second line\n",
    "this is third line\n",
    "this is fourth line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is first line\r\n",
      "this is second line\r\n",
      "this is third line\r\n",
      "this is fourth line"
     ]
    }
   ],
   "source": [
    "cat text.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스파크에서는 연산 과정을 클러스터 전체에 걸쳐 자동으로 병렬화 해 분산 배치된 연산 작업들의 모음으로 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모음은 탄력적인 분산 데이터 셋트 혹은 RDD(Resilient Distributed Dataset) 라고 부릅니다. \n",
    "RDD는 분산 데이터와 연산을 위한 스파크의 핵심적인 개념!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텍스트 파일로 부터 RDD를 하나 만들어보고 간단한 분석을 해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lines 라는 이름의 RDD를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = sc.textFile(\"text.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파이썬으로 줄 수 세기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 RDD의 아이템 갯수를 센다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 RDD의 첫번째 아이템, 이 예제에서는 text.txt 의 첫번째 라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'this is first line'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.first() # RDD의 첫번째 아이템. , text.txt 의 첫번째 라인 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파이썬 필터링 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 단어만 들어있는 라인을 filtering 해봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pythonLines = lines.filter(lambda line : \"first\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'this is first line'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pythonLines.first()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
