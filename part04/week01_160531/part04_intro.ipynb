{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빅바이오 진행 사항과 파트4 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 빅바이오 스터디의 목적 \n",
    "\n",
    "- 빅데이터을 활용한 바이오인포매틱스 + 통계기초 + 딥러닝 실습에 대한 스터디입니다.\n",
    "\n",
    "## 빅바이오의 지금까지 진행 사항\n",
    "\n",
    "### 초심자들도 참여하실 수 있도록 기초부터 진행\n",
    "\n",
    "- 통계기초\n",
    "- Hadoop\n",
    "- Learning spark\n",
    "   \n",
    "### 이전 스터디인 딥바이오와 연계된 실습\n",
    "- 유전체 데이터를 활용한 암종류 분류모델 개발 실습\n",
    "- 딥러닝 오픈소스를 theano  에서 tensorflow를 변경\n",
    "- mRNA에서 다른 다양한 유전체 데이터로 시도 예정\n",
    "\n",
    "\n",
    "## 파트4의 진행 방향과 목적 \n",
    "- 유전체 데이터 전처리를 빅데이터 오픈소스인 Hadoop과 HBase를 활용하였지만 여러 문제점 발견\n",
    "    - 여러대의 장비가 필요\n",
    "    - 오픈소스를 다룰 수 있는 기술 필요\n",
    "    - TCGA에서 데이터 수집 - 많은 수작업 필요\n",
    "    - 전처리 프로그램 작성이 필요\n",
    "\n",
    "\n",
    "- 공개된 유전체 데이터(TCGA)를 구글 지노믹스로 전처리 시도\n",
    "    - 바이오데이터 분석가들에게 금전적인 문제와 IT기술의 능력 부족 문제를 좀 해결에 도움??\n",
    "    - 필요없는 수작업을 줄임\n",
    "    - 데이터 전처리와 tensorflow와의 연동이 쉽게 될거라고 기대해봄.\n",
    "\n",
    "\n",
    "- Hadoop의 병렬처리( MapReduce)와 Spark를 활용한 고급 알고리즘 개발 능력 배양\n",
    "    - 여러분들이 적극적인 참여가 필요함.\n",
    "    - 각각의 장에 hadoop과 spark 코드가 같이 있지만, 한쪽 코드만 발표해도 됨.\n",
    "\n",
    "\n",
    "- 기대 효과\n",
    "    - 효과적인 바이오 데이터 분석과 다른 분야 분석에 도움이 되지 않을까 생각됨.\n",
    "    - 향후 데이터 분석 서비스 개발이나 창업에 도움이 되지 않을까 생각됨. \n",
    "        - 뇌영상 사진 데이터를  머신러닝(딥러닝포함)으로 학습해서 치매 진단 서비스가 오픈 예정( 연대 세브란스 )\n",
    "        - 의료 데이터 분석서비스가 돈이 되는 시기가 왔음.\n",
    "        - 병원 종속적인 것은 함정임.\n",
    "        \n",
    "## 빅바이오 스터디 정리 발표 계획\n",
    "- 구글 코리아에 장소 지원 요청하고 \n",
    "- 안될시 NaveD2 지원센터에서 \n",
    "- 내용 : 구글 genome부터 tensorflow까지 \n",
    "    \n",
    "        \n",
    "## 지금까지 빅바이오 스터디를 하면서 느낀점.\n",
    "\n",
    "- 유전체 데이터는 빅데이터가 아니라고 판단됨.\n",
    "    - 데이터의 크기는 거대하지만, 특정 사건(암종류)별 샘플(암환자)수가 적음\n",
    "    - mRNA의 종류는 2만개가 넘고,  모든 암환자의 합은 만천여명 정도, 개별 암의 환자수는 십수명 ~ 천여명으로 다양함\n",
    "    - 각각의 특정 사건(암종류)별로 동일한 데이터 추출과정과 데이터 분석방법이 다름 \n",
    "        - 데이터의 상호 연광성이 없어보임.\n",
    "    - 파편화가 심각한 거대한 데이터셋임 => 다루기도 힘들고 분석하기 힘듬\n",
    "    - 유전체 분석 실무( 업체분 )자분들이 초기에는 참여하다가 지금은 거의 참석하지 않음.\n",
    "\n",
    "\n",
    "- 유전체 데이터는 더 많아야함.\n",
    "    - 1000genomes 사이트에  2천명정도가 있는지만, 더 많은 데이터를 수집 목표로 프로젝트 진행중( ? )\n",
    "    - 향후 지금보다 더 많은 데이터를 다루는 기술이 필요.\n",
    "    \n",
    "\n",
    "        \n",
    "## 당부의 말\n",
    "\n",
    "- 저희는 강의가 아닌 스터디로 진행\n",
    "    - 모든 것을 알고 진행하는 것이 아닌 공부하면서 서로 알아가는 과정임.\n",
    "    - 스터디 첫날이 가장 배울것이 없음.\n",
    "    - 적극적인 발표만이 실력향상에 도움이 됨.\n",
    "- 뒷풀이는 커피숍에서~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
